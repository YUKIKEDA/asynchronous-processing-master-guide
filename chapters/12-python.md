# ç¬¬12ç« : Python

> ğŸ¯ **ã“ã®ç« ã®ç›®æ¨™**: Pythonã®GILï¼ˆGlobal Interpreter Lockï¼‰ã‚’ç†è§£ã—ã€threadingã€multiprocessingã€asyncioã®ä½¿ã„åˆ†ã‘ã‚’å­¦ã¶

---

## 12.1 Pythonã®GILï¼ˆGlobal Interpreter Lockï¼‰

### GILã¨ã¯

**GILï¼ˆGlobal Interpreter Lockï¼‰**ã¯ã€CPythonï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ãªPythonå®Ÿè£…ï¼‰ã«å­˜åœ¨ã™ã‚‹ãƒŸãƒ¥ãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã§ã€ä¸€åº¦ã«1ã¤ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã ã‘ãŒPythonãƒã‚¤ãƒˆã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«åˆ¶é™ã—ã¾ã™ã€‚

```mermaid
flowchart TB
    subgraph GIL_CONCEPT["GILã®æ¦‚å¿µ"]
        GIL["GIL<br/>(Global Interpreter Lock)"]
        
        T1["ã‚¹ãƒ¬ãƒƒãƒ‰1"]
        T2["ã‚¹ãƒ¬ãƒƒãƒ‰2"]
        T3["ã‚¹ãƒ¬ãƒƒãƒ‰3"]
        
        INTERPRETER["Pythonã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿"]
    end
    
    T1 -->|"GILå–å¾—"| GIL
    T2 -.->|"å¾…æ©Ÿ"| GIL
    T3 -.->|"å¾…æ©Ÿ"| GIL
    
    GIL --> INTERPRETER
    
    NOTE["åŒæ™‚ã«å®Ÿè¡Œã§ãã‚‹ã®ã¯<br/>1ã¤ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã ã‘"]
```

### ãªãœGILãŒå­˜åœ¨ã™ã‚‹ã®ã‹

GILã¯ä»¥ä¸‹ã®ç†ç”±ã§å°å…¥ã•ã‚Œã¾ã—ãŸï¼š

```mermaid
flowchart TB
    subgraph GIL_REASONS["GILãŒå­˜åœ¨ã™ã‚‹ç†ç”±"]
        R1["ãƒ¡ãƒ¢ãƒªç®¡ç†ã®ç°¡ç´ åŒ–<br/>å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆã®<br/>ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•æ€§"]
        R2["Cæ‹¡å¼µã®äº’æ›æ€§<br/>Cè¨€èªã§æ›¸ã‹ã‚ŒãŸ<br/>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã®çµ±åˆ"]
        R3["ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰æ€§èƒ½<br/>ãƒ­ãƒƒã‚¯ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰<br/>ã‚’æœ€å°åŒ–"]
    end
```

```python
# å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆã®ä¾‹
import sys

a = []
b = a  # å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆãŒå¢—åŠ 

print(sys.getrefcount(a))  # 3 (a, b, getrefcountå¼•æ•°)

# GILãŒãªã„ã¨ã€è¤‡æ•°ã‚¹ãƒ¬ãƒƒãƒ‰ãŒåŒæ™‚ã«å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆã‚’
# å¤‰æ›´ã—ã‚ˆã†ã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ç«¶åˆãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
```

### GILã®å½±éŸ¿

```mermaid
flowchart TB
    subgraph GIL_IMPACT["GILã®å½±éŸ¿"]
        subgraph CPU_BOUND["CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†"]
            CPU1["ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚‚<br/>ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œãªã„"]
            CPU2["1ã‚³ã‚¢ã—ã‹ä½¿ãˆãªã„"]
            CPU3["multiprocessingã‚’<br/>ä½¿ã†ã¹ã"]
        end
        
        subgraph IO_BOUND["I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†"]
            IO1["I/Oå¾…ã¡ä¸­ã¯<br/>GILã‚’è§£æ”¾"]
            IO2["ä»–ã®ã‚¹ãƒ¬ãƒƒãƒ‰ãŒ<br/>å®Ÿè¡Œå¯èƒ½"]
            IO3["threadingã§<br/>åŠ¹æœã‚ã‚Š"]
        end
    end
```

### CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã§ã®æ¤œè¨¼

```python
import threading
import time

def cpu_bound_task(n):
    """CPUãƒã‚¦ãƒ³ãƒ‰ãªå‡¦ç†"""
    count = 0
    for i in range(n):
        count += i
    return count

# ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰
def single_thread():
    start = time.time()
    cpu_bound_task(50_000_000)
    cpu_bound_task(50_000_000)
    print(f"ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰: {time.time() - start:.2f}ç§’")

# ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰
def multi_thread():
    start = time.time()
    t1 = threading.Thread(target=cpu_bound_task, args=(50_000_000,))
    t2 = threading.Thread(target=cpu_bound_task, args=(50_000_000,))
    
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    
    print(f"ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰: {time.time() - start:.2f}ç§’")

single_thread()  # ç´„ 3.5ç§’
multi_thread()   # ç´„ 3.5ç§’ â† GILã®ãŸã‚é€Ÿããªã‚‰ãªã„ï¼
```

```mermaid
sequenceDiagram
    participant T1 as ã‚¹ãƒ¬ãƒƒãƒ‰1
    participant GIL as GIL
    participant T2 as ã‚¹ãƒ¬ãƒƒãƒ‰2
    
    Note over T1,T2: CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†
    
    T1->>GIL: GILå–å¾—
    T1->>T1: è¨ˆç®—å‡¦ç†
    Note over T2: å¾…æ©Ÿ...
    T1->>GIL: GILè§£æ”¾
    
    T2->>GIL: GILå–å¾—
    T2->>T2: è¨ˆç®—å‡¦ç†
    Note over T1: å¾…æ©Ÿ...
    T2->>GIL: GILè§£æ”¾
    
    Note over T1,T2: äº¤äº’ã«å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚<br/>ä¸¦åˆ—åŒ–ã®æ©æµãªã—
```

### I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã§ã®æ¤œè¨¼

```python
import threading
import time
import urllib.request

def io_bound_task(url):
    """I/Oãƒã‚¦ãƒ³ãƒ‰ãªå‡¦ç†"""
    with urllib.request.urlopen(url) as response:
        return response.read()

urls = [
    "https://example.com",
    "https://example.org",
    "https://example.net",
]

# ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰
def single_thread():
    start = time.time()
    for url in urls:
        io_bound_task(url)
    print(f"ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰: {time.time() - start:.2f}ç§’")

# ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰
def multi_thread():
    start = time.time()
    threads = [threading.Thread(target=io_bound_task, args=(url,)) 
               for url in urls]
    
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    
    print(f"ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰: {time.time() - start:.2f}ç§’")

single_thread()  # ç´„ 1.5ç§’
multi_thread()   # ç´„ 0.5ç§’ â† I/Oå¾…ã¡ä¸­ã¯GILã‚’è§£æ”¾ã™ã‚‹ãŸã‚é€Ÿããªã‚‹ï¼
```

```mermaid
sequenceDiagram
    participant T1 as ã‚¹ãƒ¬ãƒƒãƒ‰1
    participant GIL as GIL
    participant T2 as ã‚¹ãƒ¬ãƒƒãƒ‰2
    participant IO as I/Oã‚·ã‚¹ãƒ†ãƒ 
    
    Note over T1,T2: I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†
    
    T1->>GIL: GILå–å¾—
    T1->>IO: I/Oé–‹å§‹
    T1->>GIL: GILè§£æ”¾ï¼ˆI/Oå¾…ã¡ï¼‰
    
    T2->>GIL: GILå–å¾—
    T2->>IO: I/Oé–‹å§‹
    T2->>GIL: GILè§£æ”¾ï¼ˆI/Oå¾…ã¡ï¼‰
    
    IO-->>T1: I/Oå®Œäº†
    T1->>GIL: GILå–å¾—
    T1->>T1: çµæœå‡¦ç†
    
    IO-->>T2: I/Oå®Œäº†
    T2->>GIL: GILå–å¾—
    T2->>T2: çµæœå‡¦ç†
    
    Note over T1,T2: I/Oå¾…ã¡ä¸­ã¯ä¸¦è¡Œå®Ÿè¡Œå¯èƒ½
```

---

## 12.2 threading ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
import threading
import time

def worker(name, delay):
    print(f"{name}: é–‹å§‹")
    time.sleep(delay)
    print(f"{name}: çµ‚äº†")

# ã‚¹ãƒ¬ãƒƒãƒ‰ã®ä½œæˆã¨å®Ÿè¡Œ
t1 = threading.Thread(target=worker, args=("Thread-1", 2))
t2 = threading.Thread(target=worker, args=("Thread-2", 1))

t1.start()
t2.start()

# ã‚¹ãƒ¬ãƒƒãƒ‰ã®å®Œäº†ã‚’å¾…ã¤
t1.join()
t2.join()

print("ã™ã¹ã¦å®Œäº†")
```

### Threadã‚¯ãƒ©ã‚¹ã®ç¶™æ‰¿

```python
import threading
import time

class MyThread(threading.Thread):
    def __init__(self, name, delay):
        super().__init__()
        self.name = name
        self.delay = delay
        self.result = None
    
    def run(self):
        """ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†"""
        print(f"{self.name}: é–‹å§‹")
        time.sleep(self.delay)
        self.result = f"{self.name}ã®çµæœ"
        print(f"{self.name}: çµ‚äº†")

# ä½¿ç”¨ä¾‹
thread = MyThread("Worker", 2)
thread.start()
thread.join()
print(f"çµæœ: {thread.result}")
```

### åŒæœŸãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–

```mermaid
flowchart TB
    subgraph SYNC_PRIMITIVES["åŒæœŸãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–"]
        LOCK["Lock<br/>æ’ä»–åˆ¶å¾¡"]
        RLOCK["RLock<br/>å†å…¥å¯èƒ½ãƒ­ãƒƒã‚¯"]
        SEMAPHORE["Semaphore<br/>åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹æ•°åˆ¶é™"]
        EVENT["Event<br/>ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥"]
        CONDITION["Condition<br/>æ¡ä»¶å¤‰æ•°"]
        BARRIER["Barrier<br/>åŒæœŸãƒã‚¤ãƒ³ãƒˆ"]
    end
```

### Lockï¼ˆãƒ­ãƒƒã‚¯ï¼‰

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        with lock:  # ãƒ­ãƒƒã‚¯ã‚’å–å¾—
            counter += 1  # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        # ãƒ­ãƒƒã‚¯ã¯è‡ªå‹•çš„ã«è§£æ”¾

threads = [threading.Thread(target=increment) for _ in range(10)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Counter: {counter}")  # 1000000ï¼ˆæ­£ç¢ºãªå€¤ï¼‰
```

### Semaphoreï¼ˆã‚»ãƒãƒ•ã‚©ï¼‰

```python
import threading
import time

# åŒæ™‚ã«3ã¤ã¾ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
semaphore = threading.Semaphore(3)

def access_resource(name):
    print(f"{name}: å¾…æ©Ÿä¸­...")
    with semaphore:
        print(f"{name}: ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­")
        time.sleep(2)
        print(f"{name}: ã‚¢ã‚¯ã‚»ã‚¹çµ‚äº†")

threads = [threading.Thread(target=access_resource, args=(f"Thread-{i}",)) 
           for i in range(10)]

for t in threads:
    t.start()
for t in threads:
    t.join()
```

```mermaid
sequenceDiagram
    participant T1 as Thread-1
    participant T2 as Thread-2
    participant T3 as Thread-3
    participant T4 as Thread-4
    participant SEM as Semaphore(3)
    
    T1->>SEM: acquire (count: 2)
    T2->>SEM: acquire (count: 1)
    T3->>SEM: acquire (count: 0)
    T4->>SEM: acquire (å¾…æ©Ÿ)
    
    Note over T1,T3: 3ã¤ãŒåŒæ™‚ã«ã‚¢ã‚¯ã‚»ã‚¹
    
    T1->>SEM: release (count: 1)
    SEM->>T4: acquireæˆåŠŸ (count: 0)
```

### Eventï¼ˆã‚¤ãƒ™ãƒ³ãƒˆï¼‰

```python
import threading
import time

event = threading.Event()

def waiter(name):
    print(f"{name}: ã‚¤ãƒ™ãƒ³ãƒˆã‚’å¾…æ©Ÿä¸­...")
    event.wait()  # ã‚¤ãƒ™ãƒ³ãƒˆãŒã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã¾ã§ãƒ–ãƒ­ãƒƒã‚¯
    print(f"{name}: ã‚¤ãƒ™ãƒ³ãƒˆå—ä¿¡ï¼")

def setter():
    print("ã‚»ãƒƒã‚¿ãƒ¼: 3ç§’å¾Œã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆ")
    time.sleep(3)
    event.set()  # ã™ã¹ã¦ã®å¾…æ©Ÿã‚¹ãƒ¬ãƒƒãƒ‰ã«é€šçŸ¥
    print("ã‚»ãƒƒã‚¿ãƒ¼: ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆå®Œäº†")

threads = [threading.Thread(target=waiter, args=(f"Waiter-{i}",)) 
           for i in range(3)]
setter_thread = threading.Thread(target=setter)

for t in threads:
    t.start()
setter_thread.start()

for t in threads:
    t.join()
setter_thread.join()
```

### ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ï¼ˆconcurrent.futuresï¼‰

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

def task(n):
    time.sleep(1)
    return n * n

# ThreadPoolExecutorã‚’ä½¿ç”¨
with ThreadPoolExecutor(max_workers=4) as executor:
    # submit: å€‹åˆ¥ã«ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
    futures = [executor.submit(task, i) for i in range(10)]
    
    # as_completed: å®Œäº†é †ã«çµæœã‚’å–å¾—
    for future in as_completed(futures):
        result = future.result()
        print(f"Result: {result}")

# map: ä¸€æ‹¬ã§ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
with ThreadPoolExecutor(max_workers=4) as executor:
    results = executor.map(task, range(10))
    for result in results:
        print(f"Result: {result}")
```

```mermaid
flowchart TB
    subgraph THREAD_POOL["ThreadPoolExecutor"]
        QUEUE["ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼"]
        
        W1["Worker 1"]
        W2["Worker 2"]
        W3["Worker 3"]
        W4["Worker 4"]
        
        RESULTS["çµæœ"]
    end
    
    TASKS["ã‚¿ã‚¹ã‚¯"] --> QUEUE
    
    QUEUE --> W1
    QUEUE --> W2
    QUEUE --> W3
    QUEUE --> W4
    
    W1 --> RESULTS
    W2 --> RESULTS
    W3 --> RESULTS
    W4 --> RESULTS
```

---

## 12.3 multiprocessing ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ãªãœmultiprocessingã‹

GILã¯ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã«å­˜åœ¨ã™ã‚‹ãŸã‚ã€ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ãªã‚‰CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚‚ä¸¦åˆ—å®Ÿè¡Œã§ãã¾ã™ã€‚

```mermaid
flowchart TB
    subgraph MULTI_PROCESS["ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹"]
        subgraph PROC1["ãƒ—ãƒ­ã‚»ã‚¹1"]
            GIL1["GIL"]
            P1_THREAD["ã‚¹ãƒ¬ãƒƒãƒ‰"]
        end
        
        subgraph PROC2["ãƒ—ãƒ­ã‚»ã‚¹2"]
            GIL2["GIL"]
            P2_THREAD["ã‚¹ãƒ¬ãƒƒãƒ‰"]
        end
        
        subgraph PROC3["ãƒ—ãƒ­ã‚»ã‚¹3"]
            GIL3["GIL"]
            P3_THREAD["ã‚¹ãƒ¬ãƒƒãƒ‰"]
        end
    end
    
    NOTE["å„ãƒ—ãƒ­ã‚»ã‚¹ã«ç‹¬ç«‹ã—ãŸGIL<br/>â†’ çœŸã®ä¸¦åˆ—å®Ÿè¡ŒãŒå¯èƒ½"]
```

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
import multiprocessing
import time
import os

def cpu_bound_task(n):
    """CPUãƒã‚¦ãƒ³ãƒ‰ãªå‡¦ç†"""
    print(f"ãƒ—ãƒ­ã‚»ã‚¹ {os.getpid()}: é–‹å§‹")
    count = 0
    for i in range(n):
        count += i
    print(f"ãƒ—ãƒ­ã‚»ã‚¹ {os.getpid()}: çµ‚äº†")
    return count

if __name__ == "__main__":
    start = time.time()
    
    # ãƒ—ãƒ­ã‚»ã‚¹ã®ä½œæˆ
    p1 = multiprocessing.Process(target=cpu_bound_task, args=(50_000_000,))
    p2 = multiprocessing.Process(target=cpu_bound_task, args=(50_000_000,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
    
    print(f"ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹: {time.time() - start:.2f}ç§’")
    # ç´„ 1.8ç§’ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã®ç´„åŠåˆ†ï¼‰
```

### ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ï¼ˆIPCï¼‰

```mermaid
flowchart TB
    subgraph IPC["ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡"]
        QUEUE["Queue<br/>FIFO ã‚­ãƒ¥ãƒ¼"]
        PIPE["Pipe<br/>åŒæ–¹å‘ãƒ‘ã‚¤ãƒ—"]
        VALUE["Value/Array<br/>å…±æœ‰ãƒ¡ãƒ¢ãƒª"]
        MANAGER["Manager<br/>å…±æœ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"]
    end
```

### Queueï¼ˆã‚­ãƒ¥ãƒ¼ï¼‰

```python
import multiprocessing

def producer(queue):
    for i in range(5):
        queue.put(f"item-{i}")
        print(f"Produced: item-{i}")

def consumer(queue):
    while True:
        item = queue.get()
        if item is None:
            break
        print(f"Consumed: {item}")

if __name__ == "__main__":
    queue = multiprocessing.Queue()
    
    prod = multiprocessing.Process(target=producer, args=(queue,))
    cons = multiprocessing.Process(target=consumer, args=(queue,))
    
    prod.start()
    cons.start()
    
    prod.join()
    queue.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
    cons.join()
```

### å…±æœ‰ãƒ¡ãƒ¢ãƒªï¼ˆValue, Arrayï¼‰

```python
import multiprocessing

def increment(counter, lock):
    for _ in range(100000):
        with lock:
            counter.value += 1

if __name__ == "__main__":
    counter = multiprocessing.Value('i', 0)  # 'i' = integer
    lock = multiprocessing.Lock()
    
    processes = [
        multiprocessing.Process(target=increment, args=(counter, lock))
        for _ in range(4)
    ]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print(f"Counter: {counter.value}")  # 400000
```

### ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«

```python
from multiprocessing import Pool
import time

def cpu_task(x):
    """CPUãƒã‚¦ãƒ³ãƒ‰ãªã‚¿ã‚¹ã‚¯"""
    result = 0
    for i in range(10_000_000):
        result += i * x
    return result

if __name__ == "__main__":
    # CPUã‚³ã‚¢æ•°ã®ãƒ—ãƒ¼ãƒ«
    with Pool() as pool:
        start = time.time()
        
        # map: ä¸€æ‹¬ã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
        results = pool.map(cpu_task, range(8))
        
        print(f"Results: {results}")
        print(f"Time: {time.time() - start:.2f}ç§’")
    
    # ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰
    with Pool(4) as pool:
        # apply_async: éåŒæœŸã§å˜ä¸€ã‚¿ã‚¹ã‚¯
        result = pool.apply_async(cpu_task, (5,))
        print(result.get())
        
        # starmap: è¤‡æ•°å¼•æ•°ã®map
        results = pool.starmap(pow, [(2, 10), (3, 5), (4, 3)])
        print(results)  # [1024, 243, 64]
```

### ProcessPoolExecutor

```python
from concurrent.futures import ProcessPoolExecutor, as_completed
import time

def cpu_task(n):
    result = sum(i * i for i in range(n))
    return result

if __name__ == "__main__":
    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(cpu_task, 1_000_000) for _ in range(8)]
        
        for future in as_completed(futures):
            result = future.result()
            print(f"Result: {result}")
```

---

## 12.4 asyncio ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### asyncioã¨ã¯

**asyncio**ã¯ã€Pythonã®éåŒæœŸI/Oãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½¿ã„ã€ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’å”èª¿çš„ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚

```mermaid
flowchart TB
    subgraph ASYNCIO["asyncio ã®æ§‹é€ "]
        EVENT_LOOP["ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—"]
        
        CORO1["ã‚³ãƒ«ãƒ¼ãƒãƒ³1"]
        CORO2["ã‚³ãƒ«ãƒ¼ãƒãƒ³2"]
        CORO3["ã‚³ãƒ«ãƒ¼ãƒãƒ³3"]
        
        IO["I/Oã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"]
    end
    
    EVENT_LOOP --> CORO1
    EVENT_LOOP --> CORO2
    EVENT_LOOP --> CORO3
    
    CORO1 <-->|"await"| IO
    CORO2 <-->|"await"| IO
    CORO3 <-->|"await"| IO
```

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
import asyncio

async def hello(name, delay):
    print(f"{name}: é–‹å§‹")
    await asyncio.sleep(delay)  # éåŒæœŸã®å¾…æ©Ÿ
    print(f"{name}: çµ‚äº†")
    return f"{name}ã®çµæœ"

async def main():
    # é †æ¬¡å®Ÿè¡Œ
    result1 = await hello("Task1", 2)
    result2 = await hello("Task2", 1)
    print(f"é †æ¬¡å®Ÿè¡Œ: {result1}, {result2}")
    
    # ä¸¦è¡Œå®Ÿè¡Œ
    results = await asyncio.gather(
        hello("TaskA", 2),
        hello("TaskB", 1),
        hello("TaskC", 3),
    )
    print(f"ä¸¦è¡Œå®Ÿè¡Œ: {results}")

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
asyncio.run(main())
```

### ã‚³ãƒ«ãƒ¼ãƒãƒ³ã€ã‚¿ã‚¹ã‚¯ã€Future

```mermaid
flowchart TB
    subgraph ASYNC_OBJECTS["asyncio ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"]
        COROUTINE["Coroutine<br/>async def ã§å®šç¾©<br/>å‘¼ã³å‡ºã™ã¨ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"]
        TASK["Task<br/>ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚ŒãŸ<br/>ã‚³ãƒ«ãƒ¼ãƒãƒ³"]
        FUTURE["Future<br/>éåŒæœŸæ“ä½œã®<br/>çµæœã‚’è¡¨ã™"]
    end
    
    COROUTINE -->|"create_task()"| TASK
    TASK -->|"ç¶™æ‰¿"| FUTURE
```

```python
import asyncio

async def my_coroutine():
    await asyncio.sleep(1)
    return "çµæœ"

async def main():
    # ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ï¼‰
    coro = my_coroutine()
    print(type(coro))  # <class 'coroutine'>
    
    # ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    task = asyncio.create_task(my_coroutine())
    print(type(task))  # <class '_asyncio.Task'>
    
    # ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤
    result = await task
    print(result)
    
    # Futureã®ç›´æ¥ä½¿ç”¨
    future = asyncio.Future()
    future.set_result("Futureçµæœ")
    result = await future
    print(result)

asyncio.run(main())
```

### ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—

```python
import asyncio

async def task(name):
    print(f"{name}: é–‹å§‹")
    await asyncio.sleep(1)
    print(f"{name}: çµ‚äº†")

# æ–¹æ³•1: asyncio.run() ï¼ˆæ¨å¥¨ï¼‰
asyncio.run(task("main"))

# æ–¹æ³•2: ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ç›´æ¥æ“ä½œ
loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)
try:
    loop.run_until_complete(task("manual"))
finally:
    loop.close()

# æ–¹æ³•3: æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
async def main():
    loop = asyncio.get_running_loop()
    print(f"Loop: {loop}")
    await task("inside")

asyncio.run(main())
```

### ã‚¿ã‚¹ã‚¯ã®ç®¡ç†

```python
import asyncio

async def long_task(name, duration):
    try:
        print(f"{name}: é–‹å§‹")
        await asyncio.sleep(duration)
        print(f"{name}: å®Œäº†")
        return f"{name}ã®çµæœ"
    except asyncio.CancelledError:
        print(f"{name}: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
        raise

async def main():
    # ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
    task1 = asyncio.create_task(long_task("Task1", 5))
    task2 = asyncio.create_task(long_task("Task2", 3))
    
    # 2ç§’å¾Œã«Task1ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    await asyncio.sleep(2)
    task1.cancel()
    
    # çµæœã‚’åé›†ï¼ˆã‚¨ãƒ©ãƒ¼ã‚‚å«ã‚€ï¼‰
    results = await asyncio.gather(
        task1, task2,
        return_exceptions=True  # ä¾‹å¤–ã‚’çµæœã¨ã—ã¦è¿”ã™
    )
    
    for result in results:
        if isinstance(result, asyncio.CancelledError):
            print("ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
        else:
            print(f"çµæœ: {result}")

asyncio.run(main())
```

### ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

```python
import asyncio

async def slow_task():
    await asyncio.sleep(10)
    return "å®Œäº†"

async def main():
    try:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§å®Ÿè¡Œ
        result = await asyncio.wait_for(slow_task(), timeout=3.0)
        print(result)
    except asyncio.TimeoutError:
        print("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
    
    # Python 3.11+: TaskGroup
    async with asyncio.TaskGroup() as tg:
        task1 = tg.create_task(asyncio.sleep(1))
        task2 = tg.create_task(asyncio.sleep(2))
    # ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ

asyncio.run(main())
```

### éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿

```python
import asyncio

# éåŒæœŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿
async def async_generator(n):
    for i in range(n):
        await asyncio.sleep(0.5)
        yield i

# éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿
class AsyncCounter:
    def __init__(self, n):
        self.n = n
        self.i = 0
    
    def __aiter__(self):
        return self
    
    async def __anext__(self):
        if self.i >= self.n:
            raise StopAsyncIteration
        await asyncio.sleep(0.5)
        result = self.i
        self.i += 1
        return result

async def main():
    # async for ã§ä½¿ç”¨
    async for value in async_generator(5):
        print(f"Generator: {value}")
    
    async for value in AsyncCounter(3):
        print(f"Counter: {value}")

asyncio.run(main())
```

### éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£

```python
import asyncio

class AsyncResource:
    async def __aenter__(self):
        print("ãƒªã‚½ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
        await asyncio.sleep(1)
        print("ãƒªã‚½ãƒ¼ã‚¹å–å¾—å®Œäº†")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        print("ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ä¸­...")
        await asyncio.sleep(0.5)
        print("ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾å®Œäº†")
    
    async def do_something(self):
        print("ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ä¸­")
        await asyncio.sleep(1)

async def main():
    async with AsyncResource() as resource:
        await resource.do_something()

asyncio.run(main())
```

---

## 12.5 asyncioã«ã‚ˆã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‡¦ç†

### TCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
import asyncio

async def tcp_client():
    reader, writer = await asyncio.open_connection('example.com', 80)
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
    request = b"GET / HTTP/1.1\r\nHost: example.com\r\n\r\n"
    writer.write(request)
    await writer.drain()
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡
    response = await reader.read(1000)
    print(f"Response: {response[:100]}...")
    
    # æ¥ç¶šã‚’é–‰ã˜ã‚‹
    writer.close()
    await writer.wait_closed()

asyncio.run(tcp_client())
```

### TCPã‚µãƒ¼ãƒãƒ¼

```python
import asyncio

async def handle_client(reader, writer):
    addr = writer.get_extra_info('peername')
    print(f"æ¥ç¶š: {addr}")
    
    while True:
        data = await reader.read(1024)
        if not data:
            break
        
        message = data.decode()
        print(f"å—ä¿¡ from {addr}: {message}")
        
        # ã‚¨ã‚³ãƒ¼ãƒãƒƒã‚¯
        writer.write(data)
        await writer.drain()
    
    print(f"åˆ‡æ–­: {addr}")
    writer.close()
    await writer.wait_closed()

async def main():
    server = await asyncio.start_server(
        handle_client, 
        'localhost', 
        8888
    )
    
    addr = server.sockets[0].getsockname()
    print(f"ã‚µãƒ¼ãƒãƒ¼èµ·å‹•: {addr}")
    
    async with server:
        await server.serve_forever()

asyncio.run(main())
```

```mermaid
sequenceDiagram
    participant Client1 as ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ1
    participant Server as ã‚µãƒ¼ãƒãƒ¼
    participant Client2 as ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ2
    
    Client1->>Server: æ¥ç¶š
    Server->>Server: handle_clienté–‹å§‹
    
    Client2->>Server: æ¥ç¶š
    Server->>Server: handle_clienté–‹å§‹
    
    Client1->>Server: ãƒ‡ãƒ¼ã‚¿é€ä¿¡
    Server->>Client1: ã‚¨ã‚³ãƒ¼è¿”ä¿¡
    
    Client2->>Server: ãƒ‡ãƒ¼ã‚¿é€ä¿¡
    Server->>Client2: ã‚¨ã‚³ãƒ¼è¿”ä¿¡
    
    Note over Server: ä¸¡æ–¹ã®æ¥ç¶šã‚’<br/>ä¸¦è¡Œã—ã¦å‡¦ç†
```

### aiohttpã«ã‚ˆã‚‹HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
import asyncio
import aiohttp

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    urls = [
        "https://example.com",
        "https://example.org",
        "https://example.net",
    ]
    
    async with aiohttp.ClientSession() as session:
        # ä¸¦è¡Œã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        tasks = [fetch(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        
        for url, result in zip(urls, results):
            print(f"{url}: {len(result)} bytes")

asyncio.run(main())
```

---

## 12.6 threading vs multiprocessing vs asyncio

### æ¯”è¼ƒè¡¨

| ç‰¹æ€§ | threading | multiprocessing | asyncio |
|------|-----------|-----------------|---------|
| ä¸¦è¡Œæ€§ | ä¸¦è¡Œï¼ˆGILåˆ¶é™ã‚ã‚Šï¼‰ | ä¸¦åˆ— | ä¸¦è¡Œ |
| ãƒ¡ãƒ¢ãƒª | å…±æœ‰ | ç‹¬ç«‹ | å…±æœ‰ |
| ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ | ä½ | é«˜ | æœ€å° |
| CPUãƒã‚¦ãƒ³ãƒ‰ | Ã— | â—‹ | Ã— |
| I/Oãƒã‚¦ãƒ³ãƒ‰ | â—‹ | â—‹ | â—‹ |
| è¤‡é›‘ã• | ä¸­ | é«˜ | ä¸­ |

```mermaid
flowchart TB
    subgraph COMPARISON["ä½¿ã„åˆ†ã‘"]
        START["å‡¦ç†ã®ç¨®é¡ã¯ï¼Ÿ"]
        
        START --> CPU{"CPUãƒã‚¦ãƒ³ãƒ‰ï¼Ÿ"}
        CPU -->|"Yes"| MP["multiprocessing<br/>çœŸã®ä¸¦åˆ—å®Ÿè¡Œ"]
        
        CPU -->|"No"| IO{"I/Oãƒã‚¦ãƒ³ãƒ‰ï¼Ÿ"}
        IO -->|"Yes"| MANY{"æ¥ç¶šæ•°ã¯ï¼Ÿ"}
        
        MANY -->|"å°‘ãªã„"| THREADING["threading<br/>ã‚·ãƒ³ãƒ—ãƒ«ã«å®Ÿè£…"]
        MANY -->|"å¤šã„"| ASYNCIO["asyncio<br/>åŠ¹ç‡çš„ã«å‡¦ç†"]
    end
```

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ¥ã®é¸æŠ

```mermaid
flowchart TB
    subgraph USE_CASES["ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ¥ã®é¸æŠ"]
        subgraph MP_USE["multiprocessing"]
            MP1["ç”»åƒ/å‹•ç”»å‡¦ç†"]
            MP2["ãƒ‡ãƒ¼ã‚¿åˆ†æ"]
            MP3["æ©Ÿæ¢°å­¦ç¿’"]
            MP4["æš—å·åŒ–/ãƒãƒƒã‚·ãƒ¥"]
        end
        
        subgraph TH_USE["threading"]
            TH1["GUIã‚¢ãƒ—ãƒª"]
            TH2["ãƒ•ã‚¡ã‚¤ãƒ«I/O"]
            TH3["å°‘æ•°ã®DBæ¥ç¶š"]
            TH4["ãƒ¬ã‚¬ã‚·ãƒ¼ã‚³ãƒ¼ãƒ‰"]
        end
        
        subgraph AS_USE["asyncio"]
            AS1["Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"]
            AS2["APIã‚µãƒ¼ãƒãƒ¼"]
            AS3["ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒãƒ¼"]
            AS4["å¤§é‡ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ"]
        end
    end
```

### çµ„ã¿åˆã‚ã›ä½¿ç”¨

```python
import asyncio
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor

def cpu_bound_sync(n):
    """CPUãƒã‚¦ãƒ³ãƒ‰ãªåŒæœŸé–¢æ•°"""
    return sum(i * i for i in range(n))

def io_bound_sync(url):
    """I/Oãƒã‚¦ãƒ³ãƒ‰ãªåŒæœŸé–¢æ•°ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰"""
    import urllib.request
    with urllib.request.urlopen(url) as response:
        return len(response.read())

async def main():
    loop = asyncio.get_running_loop()
    
    # CPUãƒã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’ãƒ—ãƒ­ã‚»ã‚¹ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œ
    with ProcessPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, 
            cpu_bound_sync, 
            10_000_000
        )
        print(f"CPU bound result: {result}")
    
    # ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°I/Oã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œ
    with ThreadPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, 
            io_bound_sync, 
            "https://example.com"
        )
        print(f"I/O bound result: {result}")

asyncio.run(main())
```

```mermaid
flowchart TB
    subgraph HYBRID["ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"]
        ASYNCIO_LOOP["asyncio ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—"]
        
        ASYNCIO_LOOP --> COROUTINES["éåŒæœŸã‚³ãƒ«ãƒ¼ãƒãƒ³<br/>(I/Oå‡¦ç†)"]
        ASYNCIO_LOOP --> THREAD_POOL["ThreadPoolExecutor<br/>(ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°I/O)"]
        ASYNCIO_LOOP --> PROCESS_POOL["ProcessPoolExecutor<br/>(CPUå‡¦ç†)"]
    end
```

---

## 12.7 async/awaitã®å†…éƒ¨å®Ÿè£…

### ã‚³ãƒ«ãƒ¼ãƒãƒ³ã®ä»•çµ„ã¿

Pythonã®`async def`ã§å®šç¾©ã•ã‚ŒãŸã‚³ãƒ«ãƒ¼ãƒãƒ³ã¯ã€å†…éƒ¨çš„ã«ã¯ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«ä¼¼ãŸä»•çµ„ã¿ã§å‹•ä½œã—ã¾ã™ã€‚

```python
import asyncio
import dis

async def simple_coroutine():
    await asyncio.sleep(1)
    return "done"

# ãƒã‚¤ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
dis.dis(simple_coroutine)
```

### ã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³ã¸ã®å¤‰æ›

```python
# ã“ã®ã‚³ãƒ«ãƒ¼ãƒãƒ³
async def example():
    print("step 1")
    await asyncio.sleep(1)
    print("step 2")
    await asyncio.sleep(1)
    print("step 3")
    return "result"

# æ¦‚å¿µçš„ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³ã«å¤‰æ›ã•ã‚Œã‚‹
class ExampleStateMachine:
    def __init__(self):
        self.state = 0
        self.result = None
    
    def send(self, value=None):
        if self.state == 0:
            print("step 1")
            self.state = 1
            return asyncio.sleep(1)  # å¾…æ©Ÿå¯¾è±¡ã‚’è¿”ã™
        elif self.state == 1:
            print("step 2")
            self.state = 2
            return asyncio.sleep(1)
        elif self.state == 2:
            print("step 3")
            self.result = "result"
            raise StopIteration(self.result)
```

```mermaid
stateDiagram-v2
    [*] --> State0: é–‹å§‹
    State0 --> State1: await sleep(1)
    State1 --> State2: await sleep(1)
    State2 --> [*]: return
    
    note right of State0: print("step 1")
    note right of State1: print("step 2")
    note right of State2: print("step 3")
```

### ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å†…éƒ¨

```python
import asyncio
import time

async def task(name, delay):
    print(f"{name}: é–‹å§‹ @ {time.time():.2f}")
    await asyncio.sleep(delay)
    print(f"{name}: çµ‚äº† @ {time.time():.2f}")

async def main():
    # è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
    tasks = [
        asyncio.create_task(task("A", 2)),
        asyncio.create_task(task("B", 1)),
        asyncio.create_task(task("C", 3)),
    ]
    
    # ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…ã¤
    await asyncio.gather(*tasks)

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å‹•ä½œã‚’å¯è¦–åŒ–
asyncio.run(main())
```

```mermaid
sequenceDiagram
    participant Loop as ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
    participant A as ã‚¿ã‚¹ã‚¯A
    participant B as ã‚¿ã‚¹ã‚¯B
    participant C as ã‚¿ã‚¹ã‚¯C
    participant Timer as ã‚¿ã‚¤ãƒãƒ¼
    
    Loop->>A: å®Ÿè¡Œé–‹å§‹
    A->>Timer: sleep(2) ç™»éŒ²
    A-->>Loop: ä¸­æ–­
    
    Loop->>B: å®Ÿè¡Œé–‹å§‹
    B->>Timer: sleep(1) ç™»éŒ²
    B-->>Loop: ä¸­æ–­
    
    Loop->>C: å®Ÿè¡Œé–‹å§‹
    C->>Timer: sleep(3) ç™»éŒ²
    C-->>Loop: ä¸­æ–­
    
    Note over Loop: ã™ã¹ã¦ä¸­æ–­çŠ¶æ…‹<br/>ã‚¿ã‚¤ãƒãƒ¼ã‚’ç›£è¦–
    
    Timer->>Loop: B ã®ã‚¿ã‚¤ãƒãƒ¼å®Œäº†
    Loop->>B: å†é–‹
    B-->>Loop: å®Œäº†
    
    Timer->>Loop: A ã®ã‚¿ã‚¤ãƒãƒ¼å®Œäº†
    Loop->>A: å†é–‹
    A-->>Loop: å®Œäº†
    
    Timer->>Loop: C ã®ã‚¿ã‚¤ãƒãƒ¼å®Œäº†
    Loop->>C: å†é–‹
    C-->>Loop: å®Œäº†
```

---

## 12.8 ã¾ã¨ã‚

ã“ã®ç« ã§ã¯ã€Pythonã®ä¸¦è¡Œå‡¦ç†ã¨éåŒæœŸå‡¦ç†ã«ã¤ã„ã¦è©³ã—ãå­¦ã³ã¾ã—ãŸã€‚

```mermaid
mindmap
    root((ç¬¬12ç« ã®ã¾ã¨ã‚))
        GIL
            CPythonå›ºæœ‰
            CPUãƒã‚¦ãƒ³ãƒ‰ã«å½±éŸ¿
            I/Oãƒã‚¦ãƒ³ãƒ‰ã¯å½±éŸ¿å°
        threading
            å…±æœ‰ãƒ¡ãƒ¢ãƒª
            GILåˆ¶é™ã‚ã‚Š
            I/Oãƒã‚¦ãƒ³ãƒ‰å‘ã‘
        multiprocessing
            ç‹¬ç«‹ãƒ¡ãƒ¢ãƒª
            çœŸã®ä¸¦åˆ—å®Ÿè¡Œ
            CPUãƒã‚¦ãƒ³ãƒ‰å‘ã‘
        asyncio
            ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰
            ã‚³ãƒ«ãƒ¼ãƒãƒ³
            é«˜åŠ¹ç‡I/O
```

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

#### 1. GILã¯CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã®ä¸¦åˆ—åŒ–ã‚’åˆ¶é™ã™ã‚‹

CPythonã®GILã«ã‚ˆã‚Šã€ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚‚CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã¯çœŸã«ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚CPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã«ã¯multiprocessingã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚

#### 2. I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã«ã¯threadingã¾ãŸã¯asyncio

I/Oå¾…ã¡ä¸­ã¯GILãŒè§£æ”¾ã•ã‚Œã‚‹ãŸã‚ã€threadingã§ã‚‚åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚å¤§é‡ã®åŒæ™‚æ¥ç¶šã‚’æ‰±ã†å ´åˆã¯asyncioãŒã‚ˆã‚ŠåŠ¹ç‡çš„ã§ã™ã€‚

#### 3. asyncioã¯ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã§é«˜ã„ä¸¦è¡Œæ€§ã‚’å®Ÿç¾

asyncioã¯ã‚³ãƒ«ãƒ¼ãƒãƒ³ã¨ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½¿ã„ã€ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã§æ•°åƒã®åŒæ™‚æ¥ç¶šã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã§ãã¾ã™ã€‚

#### 4. ç”¨é€”ã«å¿œã˜ã¦é©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ

- CPUãƒã‚¦ãƒ³ãƒ‰ â†’ multiprocessing
- I/Oãƒã‚¦ãƒ³ãƒ‰ï¼ˆå°‘æ•°ï¼‰â†’ threading
- I/Oãƒã‚¦ãƒ³ãƒ‰ï¼ˆå¤šæ•°ï¼‰â†’ asyncio
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ â†’ asyncio + ProcessPoolExecutor/ThreadPoolExecutor

---

## ğŸ“ ç·´ç¿’å•é¡Œ

1. **GILãŒCPUãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã¨I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã«ä¸ãˆã‚‹å½±éŸ¿ã®é•ã„ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚**
   
   ãƒ’ãƒ³ãƒˆï¼šGILãŒè§£æ”¾ã•ã‚Œã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦è€ƒãˆã¦ãã ã•ã„ã€‚

2. **ä»¥ä¸‹ã®å‡¦ç†ã‚’threadingã€multiprocessingã€asyncioãã‚Œãã‚Œã§å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚**
   
   å‡¦ç†å†…å®¹ï¼š5ã¤ã®URLã‹ã‚‰åŒæ™‚ã«HTTPãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹

3. **ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã®å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã—ã€ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚**

   ```python
   import asyncio
   
   async def fetch_data():
       import time
       time.sleep(5)  # ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å‡¦ç†
       return "data"
   
   async def main():
       result = await fetch_data()
       print(result)
   
   asyncio.run(main())
   ```
   
   ãƒ’ãƒ³ãƒˆï¼šasyncioã§ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å‡¦ç†ã‚’ã©ã†æ‰±ã†ã¹ãã‹è€ƒãˆã¦ãã ã•ã„ã€‚

4. **ProcessPoolExecutorã¨ThreadPoolExecutorã‚’asyncioã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ã†åˆ©ç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚**
   
   ãƒ’ãƒ³ãƒˆï¼šrun_in_executorã®ä½¿ã„æ–¹ã«ã¤ã„ã¦è€ƒãˆã¦ãã ã•ã„ã€‚

5. **ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™éåŒæœŸWebã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚**
   - 10å€‹ã®URLã‹ã‚‰åŒæ™‚ã«HTMLã‚’å–å¾—
   - å„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚µã‚¤ã‚ºã‚’å‡ºåŠ›
   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ5ç§’ï¼‰ã‚’è¨­å®š
   - ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ä»–ã®URLã®å‡¦ç†ã‚’ç¶™ç¶š
   
   ãƒ’ãƒ³ãƒˆï¼šaiohttpã¨asyncio.gatherã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

---

## ğŸ”— æ¬¡ã®ç« ã¸

[ç¬¬13ç« : Rust](./13-rust.md) ã§ã¯ã€Rustã®æ‰€æœ‰æ¨©ã‚·ã‚¹ãƒ†ãƒ ã¨éåŒæœŸå‡¦ç†ã€Futureãƒˆãƒ¬ã‚¤ãƒˆã€tokio/async-stdã«ã¤ã„ã¦è©³ã—ãå­¦ã³ã¾ã™ã€‚

---

[â† ç›®æ¬¡ã«æˆ»ã‚‹](../index.md) | [â† å‰ç« : JavaScript/TypeScript](./11-javascript.md)

